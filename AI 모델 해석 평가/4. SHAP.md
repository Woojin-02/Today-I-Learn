# SHAP

* 개별 예측값 결과에 대한 근거를 제시할 때 사용한다.
* SHAP로 개별 예측값 결과가 나온 근거를 설명하고, ICE로 예측값 결과를 원하는 쪽으로 바꾸기 위해선 어떤 변수를 바꿔야 하는지 제시할 수 있다.

### 1. Shapley Value, 기여도

* 모든 가능한 조합에서, 하나의 feature에 대한 평균 기여도를 계산한 값

* 데이터 한 건에 대해 예측한 값과 모든 예측값의 평균의 차이가 핵심이다.
    * 예를 들어, 전체 평균 10만 대비 8만으로 예측했을 때, -2만이 발생하는 데에 기여한 feature가 중요하다.
* 각 변수는 변수가 1이냐 0이나, 혹은 값이 크냐 작냐에 따라 +3만 혹은 -5만을 발생시킬 수 있다.
    * 거리가 500m 이하면 +3만, 근처에 화장실이 없으면 -5만의 차이를 발생시키는데 해당 변수가 기여할 수 있다는 의미다.
 
**기여도 구하는 법**
1. 기여도를 구하고자 하는 변수는 고정시켜두고, 나머지 변수들로 가능한 모든 조합을 구성한다. 이때 조합은 2 ** n이며, n은 변수의 수다.
2. 1번 조합의 기여도 = [조합1]에 대한 예측값 - [조합1에서 기여도를 구하려는 변수를 제외한 후 구한] 예측값
3. `예를 들어 거리가 500이하 = 1, 화장실 여부 = 0, 기여도를 부하려는 변수 => 8만` 이고 `거리가 500이하 = 1, 화장실 여부 = 0 => 9만`이면 8만 - 9만 = -1만으로, -1만이 기여도가 된다.
4. 이 방법으로 모든 조합의 기여도를 구하고, 각각의 기여도에 따른 가중치를 곱해 최종 기여도를 구한다.
5. 이때 예측값을 도출하는 데에 사용한 변수가 많으면 많을 수록 가중치가 더 높게 측정된다.


* 기여도 구하는 법을 식으로 나타내면 아래와 같다.

  ![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/9c785fbd-586c-45e7-9cda-1b317e6f5cdb)

### 2. 기여도 구해보기

```python
!pip install shap

import shap
```

**1. Tree 기반 알고리즘 => TreeExplainer**
* XGB는 사용 불가
```python
# 모델 생성 후 진행

# SHAP 값으로 모델의 예측 설명하기
explainer1 = shap.TreeExplainer(model)
shap_values1 = explainer1.shap_values(x_train)

# 특정 데이터에 대한 설명
x_train.iloc[0:1,:]
# 예측하기 위해서는 입력데이터(x)가 2차원이어야 함
pred = model.predict(x_train.iloc[0:1,:])

display(x_train.iloc[0:1,:])  # 실제 데이터(설명하고 싶은 데이터)
display(pd.DataFrame(shap_values1[0:1, :], columns = list(x_train)))  # 각각의 기여도
# 만약 변수 x1의 기여도 값이 -2.203248라면 그만큼 예측값을 내리는데에 기여했다는 의미
# 만약 변수 x2의 기여도 값이 0.445...라면 그만큼 예측값을 올리는데에 기여했다는 의미

# 그래프 그리기
# y_train의 평균 구하기
explainer1.expected_value

shap.initjs() # javascript 시각화 라이브러리 --> colab에서는 모든 셀에 포함시켜야 함. 로컬에서 실행할 때는 세션에서 한번만 실행하면 됨

# force_plot(전체평균, shapley_values, input)
shap.force_plot(explainer1.expected_value, shap_values1[0, :], x_train.iloc[0,:])  # 1차원 데이터를 넣어야 함
```

**2. SVM => KernelExplainer**

**3. Deep Learning => DeepExplainer**

**4. 그 외 일반 알고리즘 => Explainer**
