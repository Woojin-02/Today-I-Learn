# Feature에 따른 예측값 변화

### 1. Individual Condifional Expectation, ICE

* 특정한 하나의 행에서 어떤 변수 X의 변화에 따른 예측값의 변화 = **변수의 영향력**
    * 데이터셋 전체의 데이터를 하나의 행에 바꿔 넣으면서 예측값이 어떻게 바뀌는지 확인한다.
    * 0번째 행에서 crim이라는 변수를 x_train에서 추출한 crim 값을 넣고 예측했을 때 나오는 예측값들의 차이가 클수록 영향력이 크다.
 
      ![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/825acf30-8057-4f94-acee-fabe7a49625a)
      ![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/9bbb78ef-9952-4209-93ee-6072d84d67b6)

    * 여러개의 ICE를 한 플롯에 그리면,
      
      ![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/d90355de-8bbf-4401-bcf2-6935a5bd4ffd)

### 2. ICE Plot 그리기

**1. ICE 한줄만 그리기**
```python
import matplotlib.pyplot as plt
import seaborn as sns

# 1. 특정 행 지정
data1 = x_train.iloc[[0]]

# 2. x_train에서 변수의 값들을 추출
x_values = x_train['변수x'].sort_values()
x_values

# 3. data1의 x변수에 2번의 값을 하나씩 넣으며 예측값을 계산
pred_x = []

for x in x_values :
    data1['변수x'] = x
    pred_x.append(model.predict(data1)[0])
pred_x  # 확인

# 4. 예측값 그래프 (x축 : 변수x, y축 : 예측값)
sns.lineplot(x = x_values, y = pred_x)
plt.ylim(y_train.min(), y_train.max())  # 실제 값의 범위 지정(np.linespace도 사용 가능)
plt.grid()
plt.show()
```
```python
def ice_plot(model, x, y, data_1row, var) :  # 모델, 전체 x_train, y_train, 특정 행, 특정 변수

    # 1. x_train에서 변수의 값들을 추출
    x_values = x[var].sort_values()

    # 2. data1의 x변수에 2번의 값을 하나씩 넣으며 예측값을 계산
    pred = []

    for v in x_values :
        data_1row[var] = v
        pred.append(model.predict(data_1row)[0])

    # 3. 예측값 그래프 (x축 : 변수x, y축 : 예측값)
    sns.lineplot(x = x_values, y = pred)
    plt.ylim(y.min(), y.max())  # 실제 값의 범위 지정
    plt.grid()
    plt.show()
```
![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/0b1b2f1b-7694-41ff-9f72-0d79a3cf04a1)

**2. ICE 여러줄 그리기**
```python
# ① x_train에서 20개의 행을 랜덤으로 뽑습니다.
data20 = x_train.sample(20, random_state = 2023)

# ③ 이들의 평균선을 추가합니다.(PDP!)

# 개별 라인차트들 -----------------------------------------------------
var = 'lstat'
pred_values = []
for i in range(20) :
    # 특정 변수의 값을 뽑아 정렬
    x_values = data20[var].sort_values()

    # 행 하나씩 추출
    data1 = data20.iloc[[i]]

    # 추출된 한 행에서, 특정 변수의 값을 하나씩 대입하고 예측
    pred = []
    for v in x_values :
        data1[var] = v
        pred.append(model.predict(data1)[0])  # [0]은 predict(data1)의 array를 없애고 값만 나오게 하기 위해 사용

    # 한 행에 대한 라인플롯, x축 : 특정 변수의 값, y축 : 예측값.
    sns.lineplot(x = x_values, y = pred, color = 'gray', linewidth = 0.3)
    plt.ylim(y_train.min(), y_train.max())  # 실제 값의 범위 지정

# ------------------------------------------------------------------------------------
# 평균선 추가 (PDP 그리기) ------------------------------------------------------------
# pred_mean = np.array(pred_values).mean(axis = 0)
# sns.lineplot(x = x_values, y = pred_mean, color = 'red', linewidth = 1, label = 'average')

plt.grid()
plt.show()
```


### 3. Partial Dependence Plots, PDP
* 각 ICE 플롯의 평균

  ![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/75ed2b5c-ea88-4105-8e3d-6fd6cb6ac587)

* 관심 feature의 값이 변할 때, 모델에 미치는 영향을 시각화한다.
* 이때 ICE 플롯 하나 하나는 하나의 인스턴스, 하나의 분석단위 라고 부른다.
  ![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/2ce4b034-3dee-407c-b025-d8e1cfb0bfab)

### 4. PDP 그리기

```python
from sklearn.inspection import PartialDependenceDisplay, partial_dependence
``

**1. 기본 PDP**
```python
var = 'lstat'
# model : 이미 만든 모델, features : 분석할 대상 feature, X : 데이터셋(x), kind 'both' : PDP, ICE 같이 그리
PartialDependenceDisplay.from_estimator(model, data20, [var], kind="both")
plt.grid()
plt.show()
```

![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/27314471-3ccd-4b34-92d3-450fd7b0d726)

```python
var = 'rm'
temp = x_train.head(3).copy()  # 값 3개만 추출

# 값으로 보기
pdp = partial_dependence(model, features = [var], X = temp, kind = 'both')
print(pdp['average'])
print(pdp['individual'])
print(pdp['values'])

# 시각
PartialDependenceDisplay.from_estimator(model, temp, [var], kind="both")
plt.grid()
plt.show()
```

![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/47bba00e-4a62-4037-b9f4-a5fa49273e3b)



**2. 두 feature의 영향력 비교**
```python
PartialDependenceDisplay.from_estimator(model, x_train, ['x1','x2']) # 리스트로 변수 입력
plt.show()
```

![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/f60ea012-e62c-45a7-90ae-2322ce575599)


**3. 두 feature와 조합 비교**
```python
PartialDependenceDisplay.from_estimator(model, x_train, [('rm','lstat')]) # 리스트 안에 튜플로 입
plt.show()
```

![image](https://github.com/Woojin-02/Today-I-Learn/assets/64728336/99dd966e-4fd2-42b3-8524-b3e42cbb08de)

