# 분류 모델 성능 평가

* 예측값이 실제 값과 많이 같을 수록 좋은 모델
* 정확히 예측한 비율로 모델 성능 평가
* = ***정확도를 높이는 것***이 핵심

### 1. 혼동행렬

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdGmqHy%2FbtqWX4EL9Ne%2FuZeK9C5sOC6YzozhjBRFFK%2Fimg.png)

* 하늘색은 맞춤, 분홍색은 틀림
* T/F는 예측의 맞음과 틀림, PN은 모델의 예측
```
TP(True Positive) : 참긍정, 병이 있다라고 예측한 환자가 실제 병을 가진 경우
TN(True Negative) : 참부정, 병이 없다라고 예측한 환자가 실제로 병이 없는 경우
FP(False Positive) : 거짓긍정, 병이 있다고 예측한 환자가 실제로는 병이 없는 경우
FN(False Negative) : 거짓부정, 병이 없다고 예측한 환자가 실제로는 병이 있는 경우
```

### 2. 평가지표

1. **Accuracy(정확도)**
* = 정분류율
* 전체 데이터 중 1과 0 모두 올바르게 예측한 비율
* TP + TN / (TP + FN + FP + TN)

2. Precision(정밀도)
* 예측 관점
* Positive로 예측한 것(TP + FP) 중에서 실제 Positive(TP)인 경우
    * = 1이라 예측한 것 중에서 정말 1인 비율
* 혼동행렬의 세로
* 맞았다고 예측했으나 그 예측이 틀린 경우
    * 병이 있다고 예측한 환자가 실제로는 병이 없는 문제
* TP / (TP + FP)

3. **Recall(재현율)**
* 민감도(Sensitivity)
* 실제 관점
* 실제 Positive인 것 중에서(TP + FN) 중에서 실제 Positive(TP)인 경우
    * 실제 1인 데이터를 1이라고 예측한 비율
* 혼동행렬의 가로
* 안 맞았다고 예측했으나 그 예측이 틀린 경우
    * 병이 없다고 예측한 환자가 실제로는 병이 있는 문제
* TP / (TP + FN)

4. Specificity(특이도)
* 실제 Negative(TN + FP) 중에서 Negative(TN)로 예측한 비율
* 혼동행렬의 가로
* TN / (TN + FP)
* 실제 병이 없는 사람 중에서 병이 없다고 예측한 사람의 비율
* 병이 있다고 예측한 환자가 실제로는 병이 없는 문제 발생

5. F1-Score
* 정밀도와 재현율의 조화평균
* 관점이 다른 경우 조화평균이 유의미함
* 이진 분류 문제에서 주로 많이 사용
* 정밀도와 재현율이 균형을 이루며 비슷한 값을 가질 때, F1 Score는 높은 값을 가짐
* target의 데이터(ex. 합격 & 불합격) 의 중요도가 비슷한 경우에 유용
* 불균형한 분포에서 모델의 성능을 더 정확하게 평가할 수 있는데 도움
*  범위 : 0 ~ 1
* 값이 클수록 모델의 성능이 더 좋다

### 3. 이중분류와 다중분류

1. 이중분류
* 대부문의 분류 모델은 이중 분류
* binary 값(0, 1)

2. 다중분류
* sklearn에서 제공하는 iris 데이터가 예시
* 3가지 이상의 데이터

### 3. 모델 평가

|분류 함수|분류 테스트|
|:---:|:---:|
|DecisionTreeClassifier|confusion_matrix|
|KNeighborsClassifier|accuracy_socre|
|LogisticRegression|precision_score|
|RandomForestClassifier|recall_score|
|XGBClassifier|f1_score|
| |confusion_matrix|

* `from sklearn.metrics`에서 호출
* `confusion_matrix`를 쓰면 혼동행렬 배열 확인 가능
* `classification_report`를 쓰면 여러 평가지표 확인 가능
* `accuracy_socre`, `classification_report`를 제외한 나머지는 `average=None` 옵션 생활화
    * average=binary가 기본 옵션이기 때문에, 다중분류모델은 에러 발생
```python
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))
print(precision_score(y_test, y_pred, average=None))
print(recall_score(y_test, y_pred, average=None))
print(f1_score(y_test, y_pred, average=None))
print(classification_report(y_test, y_pred))
```
