# 회귀 모델 성능 평가

* 예측한 값과 실제 값의 차이(=오차)로 모델 성능을 평가
* = ***오차를 줄이는 것***이 핵심

### 1. 실젯값, 평균값, 예측값

1. 실젯값
* 실제로 예측하고 싶은 값, target, 목표값
* 실젯값과 비교해서 모델의 성능을 평가
* **오차 = 실젯값과 예측값의 차이**

2. 평균값
* 이미 존재하고 있는 평균으로 예측한 값
* 최소한 평균값보단 실제값에 가까운 예측값이 목표
* 모델의 예측값이 **평균값보다 오차를 얼마나 더 줄였는지** 중요

3. 예측값
* 모델로 새롭게 예측한 값
* 예측값이 얼마나 정확한지 알고 싶은 상황 -> 아무리 못해도 평균값보다는 좋아야 함
* 모델이 **평균값보다 얼마나 잘 예측했을지**가 중요

### 2. 오차
* 회귀모델의 성능은 오차의 크기로 평가
    * 오차 = 실제값과 예측값의 차이
* 오차를 쭉 나열하기보다 하나의 값으로 표현해야 대화가 쉬움 -> **오차평균**
* 값이 작을수록 모델 성능이 좋음(Error이기 때문에 작은 것이 좋다)

1. 오차합
* 오차 제곱의 합(SSE, Sum Squared Error)
* 오차 절대값의 합

2. 오차 제곱의 합
* **MSE**(Mean SSE) : 오차 제곱의 합의 평균
* **RMSE**(Root MSE) : MSE가 제곱임으로, 루트를 사용해 일반적인 값으로 표현

3. 오차 절대값의 합
* **MAE**(Mean Absolute Error) : 오차 절대값의 합의 평균
* MAPE(Mean Absolute Precentage Error) : 오차 비율

### 3. 결정계수

1. 오차를 바라보는 관점
* SST(Sum Squared Total)
    * 전체 오차
    * 실제값 - 평균값
    * SST보다 오차가 크면 안됨. 일종의 마지노선.
    * SST = SSR + SSE
* SSR(Sum Squared Regression)
    * 전체 오차 중에서 회귀식이 잡아낸 오차
    * 예측값 - 평균값
    * SSR 만큼 평균보다 오차를 줄임
* SSE(Sum Squared Error)
    * 전체 오차 중에서 회귀식이 여전히 잡아내지 못한 오차
    * 앞으로 줄여야 할 오차
    * 실제값 - 예측값
    * SSE만큼 오차를 줄여야 실제값과 일치함

2. 결정계수 R2
* 모델 성능을 잘 해석하기 위해서 만든 MSE의 표준화된 버전
* 전체 오차 중에서 회귀식이 잡아낸 오차의 비율(0~1 사이)
* `오차의 비` or `설명력`
* `R2 = 1`  =  `MSE = 0` = 모델이 데이터를 완벽하게 학습함
* R2 = (SSR / SST) = (1 - SSE / SST)
* 숫자가 클수록(1에 가까울수록) 좋음

### 3. 모델 평가

|회귀 함수|회귀 테스트|
|:---:|:---:|
|LinearRegression|mean_absolute_error|
|KNeighborsRegressor|mean_squared_error|
|DecisionTreeRegressor|root_mean_squared_error|
|RandomForestRegressor|classifimean_absolute_percentage_errorcation_report|
|XGBRegressor|r2_score|

* `from sklearn.metrics`에서 호출
* 단, RMSE(root_mean_squared_error)의 경우, mean_squared_error의 제곱근을 구하는 식이 필요
```python
# 예시
from sklearn.metrics import mean_squared_error

# 방법 1
print(mean_squared_error(y_test, y_pred) ** (1/2))
# 방법 2
print(mean_squared_error(y_test, y_pred, squared=False))
```