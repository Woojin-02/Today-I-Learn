# Linear Regression

* ***회귀 모델에서만 사용 가능***
* feature Engineering(불필요한 변수 제거) 필요
    * 변수가 많으면, 그 변수에 무조건 가중치가 할당되기 때문에 무조건 r2값이 높게 도출됨
    * 제대로 된 값을 얻으려면 필요한 변수만 선택
```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score
```

### 1. 선형 회귀
* y = ax + b
    * a = 기울기(또는 가중치) 정도를 결정. a가 크면 기울기가 가파르다.
    * b = 절편 또는 편향

* 데이터는 항상 y=x처럼 최선의 직선이 그어지지 않는다.
    * y = ax + b에서 최선의 기울기 a와 절편 b를 결정하는 방법을 `선형회귀`라고 함
    * 이때 그리는 직선 = `회귀선`

### 2. 회귀 모델
* 최적의 회귀 모델 = **전체 데이터의 오차 합이 최소**가 되는 모델
* 오차 합이 최소가 되는 가중치와 편향을 찾는 것
* MSE(Mean Squared Error)

### 3. 단순 회귀, 다중 회귀
* 독립변수 개수로 `단순회귀`, `다중회귀`로 분류

1. 단순 회귀(Simple Regression)
* 독립변수 하나가 종속 변수에 영향을 미치는 선형 회귀
* x 값 하나만으로 y값을 설명
* y{hat} = ax + b

2. 다중 회귀(Multiple Regression)
* 여러 독립변수가 종속 변수에 영향을 미치는 선형 회귀
* 여러개의 x값으로 y값을 설명
* y{hat} = a1x + a2x + a3x + ... + anx + b

### 4. 회귀계수

* **모델 학습 후** 회귀 계수 확인 가능
* 회귀계수 값들을 이용해 회귀식을 만들 수 있음
* coef_ : 회귀계수(가중치)
    * 단순 회귀는 하나만, 다중 회귀는 array의 형태로 가중치 출력
    * 가중치의 크기를 보고 어느 요인의 가중치가 가장 큰지(영향을 많이 미치는지), 그렇지 않은지 확인 가능
* intercept_ : 편향
    * 단순 회귀, 다수 회귀 모두 하나의 값만 출력

```python
print(model.coef_)
print(model.intercept_)
```

### 5. 다중공선성 확인
* 다중 공선성
    * 독립 변수의 일부가 다른 독립 변수의 조합으로 표현될 수 있는 경우
    * 독립 변수들이 서로 독립이 아니라 상호상관관계가 강한 경우  
* 다중 공선성 여부 확인
    * y를 제거한 데이터프레임에서 각 요소들을 임의의 y로 설정하고 나머지 x에 대한 r2_score의 값 구하기
    * 만약 r2 값이 높으면 다중 공선성이 높기 때문에 그 x는 제거하는 것이 좋음
* 데이터에 따라 변수의 개수가 다르니, 일일히 다중공선성을 확인하는 것은 비효율적일 수도 있음
* 선택과 집중으로 데이터를 처리해야 함
