# Word Embedding

* 고차원 저밀도 백터를 저차원 고밀도 벡터로 변환

### encoding
 * 아날로그를 디지털로 전환하는 것
 * 현실세계에 존재하는 것들을 0과 1로 변환하는 규칙을 encoding, 이걸 역으로 해제하는 것을 decoding이라고 함
 * Embedding을 사용해서 word to vector(Word2Vec) 진행

### Word2Vec
 * 원핫인코딩은 90도(직각) 앵글 값이기 때문에 유사성이 없다.
 * 따라서 유사성을 보존하는 Embedding이 필요.
