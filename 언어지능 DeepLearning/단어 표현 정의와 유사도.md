# 단어 표현 정의와 유사도

### 1. 단어 표현 방법
* One-Hot Encoding : 단어 수가 매우 많아서 고차원 저밀도 벡터를 구성하게 됨
* -> 적절하지 않음
* 분포 가설 사용

### 2. 단어 표현
* 텍스트가 얼마나 유사한지를 표현하는 방식
* 단어를 TF-IDF를 이용해서 벡터화하는 사전 작업 필요
    * 이 값은 자카드 유사도를 제외한 모든 유사도 판단에서 사용
    * 자카드 유사도는 벡터화없이 바로 유사도 측정이 가능

### 3. 자카드 유사도(Jaccard Similarity)
* = 자카드 지수
* 두 문장을 각각 단어의 집합으로 만든 뒤 두 집합을 통해 유사도 측정
* 0 ~ 1 사이의 값
```python
## accuracy score로 JaccardSimilarity를 판단
## 같은 위치에 얼마나 중첩되느냐

import numpy as np
from sklearn.metrics import accuracy_score

# print(accuracy_score(np.array([]), np.array([])))

print(accuracy_score(np.array([1,3,2]), np.array([1,4,5]))) # 두개가 얼마나 비슷한지 확인하고 확률을 구함
print(accuracy_score(np.array([1,3,2]), np.array([4,1,5])))
print(accuracy_score(np.array([1,1,0,0]), np.array([1,1,0,2])))
print(accuracy_score(np.array([1,0,1,0]), np.array([1,1,0,2])))
```

### 4. 코사인 유사도(Cosine Similarity)
* 두 개의 벡터값에서 코사인 각도를 구하는 방법
* -1 ~ 1 사이 값
```python
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer # 한글 문장을 보고 key를 뽑아내고 벡터로 만든다
sentence=("오늘도 폭염이 이어졌는데요, 내일은 반가운 비 소식이 있습니다.",
         "오늘도 폭염이 이어졌는데요, 내일은 반가운 비 소식이 있습니다!",
         "폭염을 피해 놀러왔다가 갑작스런 비로 망연자실하고 있습니다."
         )
tfidf_vectorizer = TfidfVectorizer(max_features=100) # 100개의 Feature 뽑기
tfidf_matrix = tfidf_vectorizer.fit_transform(sentence) # 문장을 벡터로 만들기

from sklearn.metrics.pairwise import cosine_similarity
print("[1] and [2]:", cosine_similarity(tfidf_matrix[0], tfidf_matrix[1]))
print("[1] and [3]:", cosine_similarity(tfidf_matrix[0], tfidf_matrix[2]))
```

### 5. 유클리디언 유사도(Euclidean Similarity)
* 두 벡터 간의 거리로 유사도를 판단
* 유클리디언 거리판단이 기준
    * 피타고리스의 직각삼각형 대각선 구하기 등 가장 최단거리

### 6. 맨하탄 유사도(Manhattan Similarity)
* 두 벡터 간의 거리로 유사도를 판단
* 맨하탄 거리판단이 기준
    * 대각선 최단거리가 아니라 장애물을 피해 직각으로 이동하는 최단 거리