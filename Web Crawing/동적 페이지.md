# 동적 웹 크롤링

1. 모듈 설치
```python
import requests  # 크롤링 모듈
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
```

2. json
 : 동적 웹 크롤링은 json 문자을 이용하여 크롤링
 : 혹은 selenium 이용
 * selenium : 브라우지를 직접 열어서 데이터를 크롤링

### 기본 웹 크롤링
* 웹 크롤링 방법
    1. 크롤링하려는 웹으로 이동
    2. F12로 개발자모드 열기
    3. NetWork 탭 이동
    4. 크롤링하려는 데이터와 관련된 항목 클릭 -> 네트워크 트래픽 발생 확인 후 클릭
        * 클릭 후에 나오는 response 탭에서 원하는 데이터인지 확인 가능
    5. Headers 탭의 request URL 복사
        * 한글이 포함되어 있는 경우 `https://meyerweb.com/eric/tools/dencoder/`에 가서 디코딩 필요
* 웹 크롤링 코드
    * url : 웹 크롤링 주소
    * response = requests.get(url) : get 형식으로 url에 요청보내고, 그 응답을 response에 저장
    * response = requests.post(url, params, header) : post 형식으로 url에 요청보내고, 그 응답을 response에 저장
    * data = response.json() : response를 json 형식으로 가공
    * pd.DataFrame(data) : 데이터프레임 생성
* 웹 크롤링 함수
```python
def crawling1(page=1): 
    # 네이버증권 금시세 URL 
    url = f'https://m.stock.naver.com/front-api/v1/marketIndex/prices?page={page}&category=energy&reutersCode=CLcv1'
    # request(URL) -> response(JSON(str)) 
    response = requests.get(url) 
    # JSON(str) > list, dict > DataFrame
    data = response.json()
    return pd.DataFrame(data)
```

### 심화


### api key


### 참고
`크롤링한 데이터를 북석하려면 가설 수립, 전처리, 시각화, 데이터 스케일링이 필요함`
* 가설 수립
* 시각화 -> 만약 스케일이 달라 차이를 보기 힘들다면 데이터 스케일링
```python
import matplotlib.pyplot as plt 
import seaborn as sns
%config InlineBacked.figure_formats={'png', 'retina'}
```
* 데이터 스케일링 
```python
from sklearn.preprocessing import minmax_scale

minmax_scale(df['열이름'])
```
* 상관관계 분석
```python
df.corr()
```